# 第3章 基礎算法與解析

## 3-1 手工概率模型

### 1. k 最近鄰（k-Nearest Neighbors, kNN）模型

**核心概念**：
對於一筆待分類的新資料點，找出訓練集中與它最近的 `k` 筆資料，使用這些「鄰居」的類別作為預測依據。

#### 📌 演算法流程：

1. 給定新樣本 `x`，計算它與訓練集中所有樣本的距離（常用歐氏距離）
2. 找出距離最近的 `k` 個樣本
3. 統計這些樣本的類別（如多數決）
4. 將最多數的類別指定給 `x`

#### ✅ 優點：

* 不需要訓練階段
* 簡單直觀

#### ❌ 缺點：

* 對高維資料效果不佳（受維度詛咒影響）
* 計算成本高（測試時須與所有資料比距離）

#### 📊 範例應用：

* 圖像分類（如手寫字辨識）
* 推薦系統中相似用戶比對

## 3-2 線性與非線性模型

### 1. 線性回歸（Linear Regression）


### 2. 非線性模型介紹（Non-Linear Models）

當資料之間的關係不是一條直線或平面能夠捕捉的時候，就需要使用**非線性模型**來擬合。

#### 🌀 常見非線性模型類型：

1. **多項式回歸（Polynomial Regression）**

2. **指數型或對數型模型**

3. **神經網路（Neural Networks）**

4. **決策樹與隨機森林**

## 3-3 合集學習
混合模型與模型變異
Bagging 與 Random Forest
Boosting 法與比較