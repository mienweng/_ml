## 第4章 評估、實作與前線討論
隨著模型構建與訓練日趨成熟，AI 系統的真正挑戰來自於評估、部署與社會影響的考量。本章將從模型效能的指標、實作中的技術問題，到 AI 的倫理與未來發展等角度，進行完整探討。

## 4-1 實作中的挑戰

### 資料品質與數據清洗

* **缺值處理**：均值填補、刪除、插值。
* **異常值移除**：Z-score 或 IQR 方法。
* **標籤一致性**：人工檢查與自動標準化。

資料品質直接影響模型準確度，資料前處理是建模前的關鍵步驟。

### 運算資源與 GPU 加速

* **CPU vs GPU**：

  * CPU：擅長邏輯控制與序列運算
  * GPU：適合並行處理，適用於深度學習
* **雲端資源**：如 Google Colab、AWS SageMaker、Azure ML Studio
* **分批訓練（Batching）與微調技巧**：減少記憶體負擔，提高效率

### 選擇模型與常見錯誤

* 選擇過於複雜的模型導致**過擬合（Overfitting）**
* 選擇過於簡單的模型導致**欠擬合（Underfitting）**
* 忽略 baseline 模型的比較（如 Logistic Regression）
* **資料洩漏（Data Leakage）**：使用了測試資料中的資訊於訓練中，造成結果不準

## 4-2 AI 的未來與偏誤思考

### 二個文明問題

AI 的快速發展造成兩種數位文明：

1. **技術文明**：掌握資料、資源與技術的人或組織。
2. **受控文明**：使用但不了解 AI 的一般公眾。

這可能造成資源不均、社會不公。

### 偏見與倫理風險

* **資料偏見**：訓練資料的不公平導致模型決策偏頗（如性別、種族歧視）
* **黑箱問題（Black-box）**：模型難以解釋，使用者難以信任
* **自動化判斷錯誤**：如自駕車、醫療誤判，風險不可忽視

### AI 與社會的融合與安全

* **法律與政策需跟上**：AI 判斷誰負責？
* **工作轉型**：機器可能取代某些勞動力，但也創造新職業（資料標註員、AI道德設計師等）
* **數位素養教育**：全民需具備基本 AI 判斷與應用能力